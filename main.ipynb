{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### First we will convert the audio into text\n"
      ],
      "metadata": {
        "id": "kEcyCPWu6018"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsb8earL6QMT",
        "outputId": "d1993aee-fcfb-432c-f430-37b2fe180586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: johnsnowlabs in /usr/local/lib/python3.10/dist-packages (5.0.9)\n",
            "Requirement already satisfied: pyspark==3.1.2 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (3.1.2)\n",
            "Requirement already satisfied: spark-nlp==5.0.2 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (5.0.2)\n",
            "Requirement already satisfied: nlu==5.0.1 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (5.0.1)\n",
            "Requirement already satisfied: spark-nlp-display==4.1 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.23.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (2.31.0)\n",
            "Requirement already satisfied: databricks-api in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (0.9.0)\n",
            "Requirement already satisfied: pydantic==1.10.11 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.10.11)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (0.4.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.28.52)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from nlu==5.0.1->johnsnowlabs) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlu==5.0.1->johnsnowlabs) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.11->johnsnowlabs) (4.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.1.2->johnsnowlabs) (0.10.9)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==4.1->johnsnowlabs) (7.34.0)\n",
            "Requirement already satisfied: svgwrite==1.4 in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==4.1->johnsnowlabs) (1.4)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.52 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (1.31.52)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->johnsnowlabs) (0.6.2)\n",
            "Requirement already satisfied: databricks-cli in /usr/local/lib/python3.10/dist-packages (from databricks-api->johnsnowlabs) (0.17.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.52->boto3->johnsnowlabs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu==5.0.1->johnsnowlabs) (2023.3.post1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (8.1.7)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==4.1->johnsnowlabs) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->spark-nlp-display==4.1->johnsnowlabs) (0.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp # Wrap around Spark NLP and NLU\n",
        "from johnsnowlabs import medical # Wrap around Healthcare NLP\n",
        "from johnsnowlabs import finance # Wrap around Finance NLP\n",
        "from johnsnowlabs import legal # Wrap around Legal NLP\n",
        "from johnsnowlabs import viz # Wrap around Spark NLP Display"
      ],
      "metadata": {
        "id": "9arkRuZc69wr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = nlp.load('en.speech2text.wav2vec2.v2_base_960h').predict(\"/content/obama.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kSoEMd7AaM",
        "outputId": "cb069921-4e6b-41fd-fa57-94c20f99a618"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "asr_wav2vec2_base_960h_4_gram download started this may take some time.\n",
            "Approximate size to download 217 MB\n",
            "[OK!]\n",
            "Warning::Spark Session already created, some configs may not take.\n",
            "Warning::Spark Session already created, some configs may not take.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWXZEBUo7DGF",
        "outputId": "d4990a60-6701-410a-f95b-322e43e7258b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WHILE ESTABLISHING A FRAMEWORK TO PROTECT OUR PLANET FROM THE RAVAGES OF CLIMATE CHANGE THIS IS IMPORTANT WORK IT HAS MADE A REAL DIFERENCE IN THE LIVES OF OUR PEOPLE AND IT COULD NOT HAVE HAPENED HAD WE NOT WORKED TOGETHER AND YET AROUND THE GLOBE WE ARE SEING THE SAME FORCES OF GLOBAL INEGRATION THAT HAVE MADE US INTERDEPENDENT ALSO EXPOSED DEP FAULT LINES IN THE EXISTING INTERNATIONAL ORDER WE SE IT IN THE HEADLINES EVERY DAY AROUND THE WORLD REFUGES FLOW ACROS BORDERS IN FLIGHT FROM BRUTAL CONFLICT FINANCIAL DISRUPTIONS CONTINUED AWAY UPON OUR WORKERS AND ENTIRE COMUNITIES THECROS BAS SWATS OF THE MADLIST BASIC SECURITY \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will split the text into small chunks\n"
      ],
      "metadata": {
        "id": "9rWRkONV7orQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spc = 0\n",
        "txt = val['text'][0]\n",
        "txt_chunks = []\n",
        "start = 0\n",
        "for i in range(len(txt)):\n",
        "  if spc == 4:\n",
        "    spc = 0\n",
        "    txt_chunks.append(txt[start:i])\n",
        "    start = i\n",
        "    continue\n",
        "  if txt[i] == \" \":\n",
        "    spc += 1\n",
        "print(txt_chunks)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsqBnr57l_R",
        "outputId": "6ed2227a-720d-4961-ff56-f505c3e29352"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['WHILE ESTABLISHING A FRAMEWORK ', 'TO PROTECT OUR PLANET ', 'FROM THE RAVAGES OF ', 'CLIMATE CHANGE THIS IS ', 'IMPORTANT WORK IT HAS ', 'MADE A REAL DIFERENCE ', 'IN THE LIVES OF ', 'OUR PEOPLE AND IT ', 'COULD NOT HAVE HAPENED ', 'HAD WE NOT WORKED ', 'TOGETHER AND YET AROUND ', 'THE GLOBE WE ARE ', 'SEING THE SAME FORCES ', 'OF GLOBAL INEGRATION THAT ', 'HAVE MADE US INTERDEPENDENT ', 'ALSO EXPOSED DEP FAULT ', 'LINES IN THE EXISTING ', 'INTERNATIONAL ORDER WE SE ', 'IT IN THE HEADLINES ', 'EVERY DAY AROUND THE ', 'WORLD REFUGES FLOW ACROS ', 'BORDERS IN FLIGHT FROM ', 'BRUTAL CONFLICT FINANCIAL DISRUPTIONS ', 'CONTINUED AWAY UPON OUR ', 'WORKERS AND ENTIRE COMUNITIES ', 'THECROS BAS SWATS OF ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will pass the sentence to be gramatically checked"
      ],
      "metadata": {
        "id": "DaCGWpY27N0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/PrithivirajDamodaran/Gramformer.git\n",
        "!pip install spacy\n",
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu4YGMwt7G4a",
        "outputId": "7fc901bf-5a13-4189-f56c-a08e35b39921"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PrithivirajDamodaran/Gramformer.git\n",
            "  Cloning https://github.com/PrithivirajDamodaran/Gramformer.git to /tmp/pip-req-build-po7pfn60\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PrithivirajDamodaran/Gramformer.git /tmp/pip-req-build-po7pfn60\n",
            "  Resolved https://github.com/PrithivirajDamodaran/Gramformer.git to commit 23425cd2e98a919384cab6156af8adf1c9d0639a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (4.33.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (0.1.99)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (0.21.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (0.18.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (2023.6.0)\n",
            "Requirement already satisfied: errant in /usr/local/lib/python3.10/dist-packages (from gramformer==1.0) (2.3.3)\n",
            "Requirement already satisfied: spacy<3,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from errant->gramformer==1.0) (2.3.9)\n",
            "Requirement already satisfied: rapidfuzz>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from errant->gramformer==1.0) (3.3.0)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->gramformer==1.0) (0.21.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->gramformer==1.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers->gramformer==1.0) (4.5.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (0.7.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (67.7.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3,>=2.2.0->errant->gramformer==1.0) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->gramformer==1.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->gramformer==1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->gramformer==1.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->gramformer==1.0) (2023.7.22)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (2.3.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting en_core_web_sm==2.3.1\n",
            "  Using cached en_core_web_sm-2.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from en_core_web_sm==2.3.1) (2.3.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.8)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.23.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2023.7.22)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz\n",
        "!tar -xvf en.tar.gz\n",
        "!!sudo apt-get install swig3.0\n",
        "!sudo pip install jamspell\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sChIYhkI9Da8",
        "outputId": "830520a1-b06e-43f6-974f-68680e65839f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-21 23:52:30--  https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bakwc/JamSpell-models/master/en.tar.gz [following]\n",
            "--2023-09-21 23:52:30--  https://raw.githubusercontent.com/bakwc/JamSpell-models/master/en.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36611828 (35M) [application/octet-stream]\n",
            "Saving to: ‘en.tar.gz.1’\n",
            "\n",
            "en.tar.gz.1         100%[===================>]  34.92M   187MB/s    in 0.2s    \n",
            "\n",
            "2023-09-21 23:52:30 (187 MB/s) - ‘en.tar.gz.1’ saved [36611828/36611828]\n",
            "\n",
            "en.bin\n",
            "Requirement already satisfied: jamspell in /usr/local/lib/python3.10/dist-packages (0.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jamspell\n",
        "jsp = jamspell.TSpellCorrector()\n",
        "assert jsp.LoadLangModel('en.bin')\n",
        "txt_chunks_corrected = []\n",
        "for i in txt_chunks:\n",
        "  print(jsp.FixFragment(i))\n",
        "  txt_chunks_corrected.append(jsp.FixFragment(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UD5NouL93yK",
        "outputId": "91a68730-df18-4210-d42a-6955618e082b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WHILE ESTABLISHING A FRAMEWORK \n",
            "TO PROTECT OUR PLANET \n",
            "FROM THE RAVAGES OF \n",
            "CLIMATE CHANGE THIS IS \n",
            "IMPORTANT WORK IT HAS \n",
            "MADE A REAL DIFFERENCE \n",
            "IN THE LIVES OF \n",
            "OUR PEOPLE AND IT \n",
            "COULD NOT HAVE HAPPENED \n",
            "HAD WE NOT WORKED \n",
            "TOGETHER AND YET AROUND \n",
            "THE GLOBE WE ARE \n",
            "BEING THE SAME FORCES \n",
            "OF GLOBAL INTEGRATION THAT \n",
            "HAVE MADE US INTERDEPENDENT \n",
            "ALSO EXPOSED DEP FAULT \n",
            "LINES IN THE EXISTING \n",
            "INTERNATIONAL ORDER WE SE \n",
            "IT IN THE HEADLINES \n",
            "EVERY DAY AROUND THE \n",
            "WORLD REFUGES FLOW ACROS \n",
            "BORDERS IN FLIGHT FROM \n",
            "BRUTAL CONFLICT FINANCIAL DISRUPTIONS \n",
            "CONTINUED AWAY UPON OUR \n",
            "WORKERS AND ENTIRE COMMUNITIES \n",
            "OTHERS BAS SWATS OF \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will translate the code into hindi and extract the pronunciation of it which is nothing but the hinglish version"
      ],
      "metadata": {
        "id": "_Rb-yB5WHok1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2YSpA4TA1sn",
        "outputId": "4bdb1fa6-c231-4db5-bb20-04c1aa0cf52c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.7.22)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "txt = txt_chunks_corrected\n",
        "result_hindi = translator.translate(txt, dest='hi')\n",
        "for i in result_hindi:\n",
        "  print(i.pronunciation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1UCP88NBUym",
        "outputId": "64ae588c-41c2-4781-9262-21188e3abf26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ek dhaancha sthaapit karate samay\n",
            "hamaare grah kee raksha ke lie\n",
            "ke vinaash se\n",
            "jalavaayu parivartan yah hai\n",
            "yah mahatvapoorn kaary hai\n",
            "ek vaastavik antar paida kiya\n",
            "ke jeevan mein\n",
            "hamaare log aur yah\n",
            "nahin ho saka\n",
            "kya hamane kaam nahin kiya tha\n",
            "ek saath aur phir bhee aasapaas\n",
            "ham jo glob hain\n",
            "ek hee taakat hona\n",
            "vaishvik ekeekaran kee vah\n",
            "hamen anyonyaashrit bana diya hai\n",
            "deeeepee kee galatee bhee ujaagar kee\n",
            "maujooda mein panktiyaan\n",
            "antarraashtreey aadesh ham esee\n",
            "yah surkhiyon mein hai\n",
            "har din ke aasapaas\n",
            "vishvabhar mein sharanaarthee pravaah\n",
            "se udaan mein seemaen\n",
            "kroor sangharsh vitteey vyavadhaan\n",
            "hamaare oopar jaaree rakha\n",
            "shramik aur sampoorn samudaay\n",
            "any bas svaats ke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will clone the audio into teh specified voice and extract audio samples."
      ],
      "metadata": {
        "id": "e-DyqguzHz2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bark\n",
        "!pip install git+https://github.com/suno-ai/bark.git\n",
        "!git clone https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "!pip install -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xenot3cBi6m",
        "outputId": "5a5fd054-f768-4f7d-8aac-10b61f7c105a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bark in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from bark) (1.28.52)\n",
            "Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from bark) (0.1.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from bark) (2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from bark) (0.16.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bark) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bark) (1.11.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from bark) (0.13.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bark) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bark) (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bark) (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->bark) (23.1)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.52 in /usr/local/lib/python3.10/dist-packages (from boto3->bark) (1.31.52)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->bark) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->bark) (0.6.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->bark) (2.0.2+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from encodec->bark) (0.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bark) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bark) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bark) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->bark) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->bark) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->bark) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bark) (2023.6.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bark) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.52->boto3->bark) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.52->boto3->bark) (1.26.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bark) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->bark) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->bark) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->bark) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bark) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.52->boto3->bark) (1.16.0)\n",
            "Collecting git+https://github.com/suno-ai/bark.git\n",
            "  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-_scpoppe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-_scpoppe\n",
            "  Resolved https://github.com/suno-ai/bark.git to commit 61710e5265cbc2f5eb098e08c6bee5d23dfff3fd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./bark-voice-cloning-HuBERT-quantizer')\n",
        "import os\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from bark.api import generate_audio\n",
        "from bark.generation import SAMPLE_RATE, preload_models, load_codec_model\n",
        "from encodec.utils import convert_audio\n",
        "from bark_hubert_quantizer.customtokenizer import CustomTokenizer\n",
        "from bark_hubert_quantizer.hubert_manager import HuBERTManager\n",
        "from bark_hubert_quantizer.pre_kmeans_hubert import CustomHubert"
      ],
      "metadata": {
        "id": "UF5GixhGC_D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "use_gpu = True if device == 'cuda' else False\n",
        "model = load_codec_model(use_gpu=use_gpu)\n",
        "\n",
        "preload_models(\n",
        "    text_use_gpu=use_gpu,\n",
        "    text_use_small=False,\n",
        "    coarse_use_gpu=use_gpu,\n",
        "    coarse_use_small=False,\n",
        "    fine_use_gpu=use_gpu,\n",
        "    fine_use_small=False,\n",
        "    codec_use_gpu=use_gpu,\n",
        "    force_reload=False\n",
        ")\n",
        "\n",
        "hubert_manager = HuBERTManager()\n",
        "hubert_manager.make_sure_hubert_installed()\n",
        "hubert_manager.make_sure_tokenizer_installed()\n",
        "\n",
        "# Load the HuBERT model\n",
        "hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n",
        "\n",
        "# Load the CustomTokenizer model\n",
        "tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth', map_location=device).to(device)"
      ],
      "metadata": {
        "id": "gWXjWg0fDBf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(result_hindi)):\n",
        "  text_prompt = result_hindi[i]\n",
        "  audio_filepath = '/content/obama10.mp3'\n",
        "\n",
        "  if not os.path.isfile(audio_filepath):\n",
        "    raise ValueError(f\"Audio file not exists ({audio_filepath})\")\n",
        "\n",
        "  wav, sr = torchaudio.load(audio_filepath)\n",
        "  wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
        "  wav = wav.to(device)\n",
        "\n",
        "  semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n",
        "  semantic_tokens = tokenizer.get_token(semantic_vectors)\n",
        "\n",
        "  # Extract discrete codes from EnCodec\n",
        "  with torch.no_grad():\n",
        "      encoded_frames = model.encode(wav.unsqueeze(0))\n",
        "  codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()\n",
        "\n",
        "  # move codes to cpu\n",
        "  codes = codes.cpu().numpy()\n",
        "  # move semantic tokens to cpu\n",
        "  semantic_tokens = semantic_tokens.cpu().numpy()\n",
        "\n",
        "  voice_filename = 'output.npz'\n",
        "\n",
        "  current_path = os.getcwd()\n",
        "  voice_name = os.path.join(current_path, voice_filename)\n",
        "\n",
        "  np.savez(voice_name, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)\n",
        "\n",
        "  # simple generation\n",
        "  audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)\n",
        "\n",
        "  # save audio\n",
        "  filepath = \"/content/out\" + str(i) + \".wav\" # change this to your desired output path\n",
        "  write_wav(filepath, SAMPLE_RATE, audio_array)"
      ],
      "metadata": {
        "id": "mIMTd8R2DDBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can view the out(1 to n).wav files under content and download them"
      ],
      "metadata": {
        "id": "4Y1HWy6uH_2L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QOAto12IGhR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}